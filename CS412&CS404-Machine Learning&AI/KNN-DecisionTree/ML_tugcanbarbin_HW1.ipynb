{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrzkxpZrCF6D"
      },
      "source": [
        "# CS 412 Machine Learning 2020 \n",
        "\n",
        "# Assignment 1\n",
        "\n",
        "100 pts\n",
        "\n",
        "## Goal \n",
        "\n",
        "The goal of this assignment \n",
        "\n",
        "*  Introduction to the machine learning experimental set up\n",
        "*  Gain experience with the Scikit library\n",
        "*  Gain experience with Decision tree and k-NN models\n",
        "\n",
        "## Dataset\n",
        "\n",
        "**Wine Quality Dataset** is a collection red and white wines with 12 attributes. The target variable is the 'quality' either 0 or 1\n",
        "\n",
        "\n",
        "## Task\n",
        "Build a decision tree and k-NN classifiers with the scikit-learn library function calls to **classify** the quality of wine as good (1) and bad (0)\n",
        "\n",
        "## Submission\n",
        "\n",
        "Follow the instructions at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18kyKgy9LiZx"
      },
      "source": [
        "# 1) Initialize\n",
        "\n",
        "First, make a copy of this notebook in your drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTJUORO9CBNq",
        "outputId": "00ee21da-ca54-4e39-8155-a502e94e50cc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount to your drive, in this way you can reach files that are in your drive\n",
        "# Run this cell\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtputkpVLt8H"
      },
      "source": [
        "# 2) Load Dataset\n",
        "To start working for your homework, take a copy of the folder, given in the below link to your own google drive. You find the train and test data under this folder.\n",
        "\n",
        "https://drive.google.com/drive/folders/1PC6M332CTdW-OOrgJ-1GU1F3UaRupka8?usp=sharing\n",
        "\n",
        "After copy the folder, copy the path of the train and test dataset to paste them in the below cell to load your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "gB1Fur5APIjQ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/My Drive/winequality-train.csv')\n",
        "test_df =pd.read_csv('/content/drive/My Drive/winequality-test.csv') # One line of code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtcu1QMXMLBN"
      },
      "source": [
        "# 3) Understand the dataset\n",
        "\n",
        "You can use the fuctions that we saw in the recitations to understand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "KjQj6XQNMd68",
        "outputId": "d07d6606-cb9a-4bc4-deb9-38f459471990",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5198, 13)\n",
            "(1299, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>wine type</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3524</th>\n",
              "      <td>8.8</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.74</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.042</td>\n",
              "      <td>15.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>0.99340</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.51</td>\n",
              "      <td>11.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2598</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.103</td>\n",
              "      <td>32.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99586</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.66</td>\n",
              "      <td>11.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>8.2</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.057</td>\n",
              "      <td>43.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.99408</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.81</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>8.9</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.53</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.101</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.99586</td>\n",
              "      <td>3.21</td>\n",
              "      <td>0.59</td>\n",
              "      <td>12.1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.28</td>\n",
              "      <td>20.4</td>\n",
              "      <td>0.041</td>\n",
              "      <td>40.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1.00020</td>\n",
              "      <td>3.14</td>\n",
              "      <td>0.38</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4537</th>\n",
              "      <td>5.7</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>20.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.99340</td>\n",
              "      <td>3.38</td>\n",
              "      <td>0.62</td>\n",
              "      <td>9.9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.044</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.99318</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.66</td>\n",
              "      <td>12.7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4846</th>\n",
              "      <td>8.2</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.29</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0.076</td>\n",
              "      <td>19.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99138</td>\n",
              "      <td>2.95</td>\n",
              "      <td>0.39</td>\n",
              "      <td>12.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4964</th>\n",
              "      <td>8.2</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2.8</td>\n",
              "      <td>0.089</td>\n",
              "      <td>11.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.99750</td>\n",
              "      <td>3.53</td>\n",
              "      <td>0.61</td>\n",
              "      <td>10.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.051</td>\n",
              "      <td>13.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.99450</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  alcohol  wine type  quality\n",
              "3524            8.8              0.23         0.74  ...     11.2          0        0\n",
              "2598            6.3              0.68         0.01  ...     11.3          1        0\n",
              "4198            8.2              0.34         0.37  ...     12.0          1        0\n",
              "3675            8.9              0.48         0.53  ...     12.1          1        1\n",
              "299             6.5              0.28         0.28  ...      8.7          0        0\n",
              "4537            5.7              0.33         0.15  ...      9.9          0        0\n",
              "1989            7.1              0.66         0.00  ...     12.7          1        1\n",
              "4846            8.2              0.34         0.29  ...     12.5          0        0\n",
              "4964            8.2              0.40         0.44  ...     10.5          1        0\n",
              "285             6.1              0.32         0.37  ...     10.5          0        0\n",
              "\n",
              "[10 rows x 13 columns]"
            ]
          },
          "execution_count": 85,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print shape of the train and test sets\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)\n",
        "\n",
        "\n",
        "# show random samples from the training data\n",
        "train_df.sample(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B93dybOMqBF",
        "outputId": "93f5bfca-484c-4df3-8142-13c954025a12",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5198 entries, 0 to 5197\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         5198 non-null   float64\n",
            " 1   volatile acidity      5198 non-null   float64\n",
            " 2   citric acid           5198 non-null   float64\n",
            " 3   residual sugar        5198 non-null   float64\n",
            " 4   chlorides             5198 non-null   float64\n",
            " 5   free sulfur dioxide   5198 non-null   float64\n",
            " 6   total sulfur dioxide  5198 non-null   float64\n",
            " 7   density               5198 non-null   float64\n",
            " 8   pH                    5198 non-null   float64\n",
            " 9   sulphates             5198 non-null   float64\n",
            " 10  alcohol               5198 non-null   float64\n",
            " 11  wine type             5198 non-null   int64  \n",
            " 12  quality               5198 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 528.0 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1299 entries, 0 to 1298\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1299 non-null   float64\n",
            " 1   volatile acidity      1299 non-null   float64\n",
            " 2   citric acid           1299 non-null   float64\n",
            " 3   residual sugar        1299 non-null   float64\n",
            " 4   chlorides             1299 non-null   float64\n",
            " 5   free sulfur dioxide   1299 non-null   float64\n",
            " 6   total sulfur dioxide  1299 non-null   float64\n",
            " 7   density               1299 non-null   float64\n",
            " 8   pH                    1299 non-null   float64\n",
            " 9   sulphates             1299 non-null   float64\n",
            " 10  alcohol               1299 non-null   float64\n",
            " 11  wine type             1299 non-null   int64  \n",
            " 12  quality               1299 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 132.1 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# print information about the datasets (Is there any missing value? or Categorical feature?)\n",
        "print(train_df.info())\n",
        "print(test_df.info())\n",
        "#There is no missing value or cathegorical feature in these data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAFQHAq8Mno1"
      },
      "source": [
        "# 4) Define train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "JjW1ZNhONNCb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# make sure you remove the labels from datasets\n",
        "\n",
        "train_labels = train_df.pop(\"quality\")\n",
        "test_labels = test_df.pop(\"quality\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fn3N4V_OlL_"
      },
      "source": [
        "# 5) FineTune Decision Tree hyper-parameters\n",
        "\n",
        "1-Splitting dataset into train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "hJlxVMTnYTTg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Split training data to 70% training and 30% validation, do not forget to use the random_state parameter\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_df,train_labels,test_size = 0.3, random_state = 1010)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNm9SC9JYXN2"
      },
      "source": [
        "2- FineTune minimum sample split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "UfTLLotIO3WX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "min_samples_splits = range(2, 50)\n",
        "\n",
        "train_results = []\n",
        "val_results = []\n",
        "for min_samples_split in min_samples_splits:\n",
        "\n",
        "  # Fit the tree using the 70% portion of the training data\n",
        "  dtClass = DecisionTreeClassifier(min_samples_split= min_samples_split, random_state= 1010)\n",
        "  dtClass.fit(x_train,y_train)\n",
        "\n",
        "  # Evaluate on Training set\n",
        "  train_acc = dtClass.score(train_df,train_labels)\n",
        "  train_results.append(train_acc)\n",
        "   \n",
        "  # Evaluate on Validation set\n",
        "  val_acc = dtClass.score(x_val,y_val)\n",
        "  val_results.append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "_jqCo52hPjkk",
        "outputId": "d5c6b549-7c38-4b98-a3e9-2dc6aeeba866",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(min_samples_splits, train_results, 'b')\n",
        "plt.plot(min_samples_splits, val_results,'r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrZSntmRYtFL",
        "outputId": "0afe9b61-aa2a-45a2-b2cc-da91b4f46629",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25  is our best minimum sample split value\n",
            "Testing Accuracy = 81.8322%\n",
            "      fixed acidity  volatile acidity  ...  alcohol  wine type\n",
            "2185            7.6              0.31  ...      9.7          0\n",
            "3193            9.2              0.92  ...      9.8          1\n",
            "4928            7.0              0.32  ...     12.8          0\n",
            "2115            7.3              0.34  ...     10.2          0\n",
            "3797            8.4              0.35  ...      9.4          0\n",
            "...             ...               ...  ...      ...        ...\n",
            "354             4.4              0.46  ...     13.1          0\n",
            "4906            6.0              0.34  ...     10.7          0\n",
            "2582            6.9              0.48  ...     12.2          0\n",
            "202             7.2              0.25  ...      9.0          0\n",
            "1736            7.1              0.65  ...      9.1          1\n",
            "\n",
            "[3638 rows x 12 columns]\n",
            "-------------------\n",
            "2185    0\n",
            "3193    0\n",
            "4928    1\n",
            "2115    0\n",
            "3797    0\n",
            "       ..\n",
            "354     0\n",
            "4906    0\n",
            "2582    1\n",
            "202     1\n",
            "1736    0\n",
            "Name: quality, Length: 3638, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Choose the best minimum split sample based on the plot\n",
        "Best_minSampl = min_samples_splits[np.argmax(val_results)]\n",
        "print(Best_minSampl, \" is our best minimum sample split value\")\n",
        "\n",
        "# Train decision tree using the full training data and the best minimum split sample\n",
        "dtClass = DecisionTreeClassifier(min_samples_split=Best_minSampl, random_state= 1010)\n",
        "dtClass.fit(train_df,train_labels)\n",
        "\n",
        "# Estimate the prediction of the test data\n",
        "test_pred = dtClass.predict(test_df) # One line of code\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Calculate accuracy of test data\n",
        "TestAcc = accuracy_score(test_labels, test_pred)\n",
        "print(\"Testing Accuracy = %.4f%%\" % (TestAcc * 100))\n",
        "print(x_train)\n",
        "print(\"-------------------\")\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_GMi20MO3lr"
      },
      "source": [
        "# 6) Apply the same procedure but using k-NN instead of decision tree\n",
        "\n",
        "For finetuning, find the best value of K to use with this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKZoNasEO9BT",
        "outputId": "ca07ee88-e622-4cd5-bb19-632846aea147",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Validation Accuracy = 81.2179%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# initialize the values of k to be a list of odd numbers between 1 and 30\n",
        "kVals = np.arange(1,30,2)\n",
        "\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "# hint: you can use accuracies.append(...) function inside the loop\n",
        "accuracies = []\n",
        "\n",
        "# loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "  # Follow what we did in decision tree part\n",
        "  model= KNeighborsClassifier(n_neighbors = k)\n",
        "  model.fit( x_train , y_train )\n",
        "  predictsKnn = model.predict(x_val)\n",
        "  accuracies.append(accuracy_score(y_val,predictsKnn))\n",
        "\n",
        "\n",
        "print(\"Best Validation Accuracy = %.4f%%\" % (np.max(accuracies)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1PtA576uw9t",
        "outputId": "9f34530d-27b0-4209-e169-d07a78d42e69",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8083140877598153  : is our accuracy score on test database\n"
          ]
        }
      ],
      "source": [
        "# Train k-NN using the full training data with the best K that you found\n",
        "model = KNeighborsClassifier(n_neighbors= kVals[np.argmax(accuracies)])\n",
        "model.fit(train_df,train_labels)\n",
        "# Testing\n",
        "predictsKnn= model.predict(test_df)\n",
        "print(accuracy_score(test_labels, predictsKnn), \" : is our accuracy score on test database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jj5HPoU5iWa",
        "outputId": "8cc72f69-7012-4a74-80d7-8b9a5ff2923a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/ML_tugcanbarbin_HW1.ipynb to html\n",
            "[NbConvertApp] Writing 321085 bytes to /content/ML_tugcanbarbin_HW1.html\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 99,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/ML_tugcanbarbin_HW1.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmL4-FHqO_sq"
      },
      "source": [
        "# 7) Notebook & Report\n",
        "\n",
        "Notebook: We may just look at your notebook results; so make sure each cell is run and outputs are there.\n",
        "\n",
        "Report: Write an at most 1/2 page summary of your approach to this problem at the end of your notebook; this should be like an abstract of a paper or the executive summary.\n",
        "\n",
        "Must include statements such as:\n",
        "\n",
        "( Include the problem definition: 1-2 lines )\n",
        "\n",
        "(Talk about any preprocessing you did, explain your reasoning)\n",
        "\n",
        "(Talk about train/val/test sets, size and how split)\n",
        "\n",
        "(State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\")\n",
        "\n",
        "(Comment on the speed of the algorithms and anything else that you deem important/interesting)\n",
        "\n",
        "\n",
        "You will get full points from here as long as you have a good (enough) summary of your work, regardless of your best performance or what you have decided to talk about in the last few lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBjX29muPFu0"
      },
      "source": [
        "# Report\n",
        "\n",
        "In this homework, we are given two datasets that has same features and label but splitted in terms of test and train. We are trying to predict the quality of a wine by using features of that wine. To achieve this prediction goal, we need to use machine learning.\n",
        "\n",
        "\n",
        "Firstly, i checked the both data's informations to see whether there are some missing informations or columns but i could not find any missing information. Then, i splitted labels from original datas, so i had four data:\n",
        "\n",
        "---->test features\n",
        "\n",
        "---->test labels\n",
        "\n",
        "---->train features\n",
        "\n",
        "---->train labels\n",
        "\n",
        "Then, i splitted the training  datas into two parts as :\n",
        "\n",
        "-Training data 70% of actual training data which is used to train my kNN and decision tree\n",
        "\n",
        "-validation data 30% of actual training data which is used to set the hyperparameters as best\n",
        "\n",
        "We have achieved to get best result with the Decision Tree Classifier with the parameter of min_sample_split = 25. Our best accuracy is 81.8322% on test data. It is not good enough but not bad either can be improved by tuning other hyperparameters.\n",
        "\n",
        "\n",
        "I used training (fit) and prediction algorithms in same code boxes. So, i could not compare just training or prediction algorithm speeds. Also, since our data is not big, i could not understand the difference of kNN and Decision Tree performance in terms of speed. However, i feel that kNN is slower than decision "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_tugcanbarbin_HW1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
