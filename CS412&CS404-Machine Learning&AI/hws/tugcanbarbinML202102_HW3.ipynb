{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tugcanbarbinML202102_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsPftUCDDurU"
      },
      "source": [
        "# CS 412 Machine Learning 2020 \n",
        "\n",
        "# Assignment 3\n",
        "\n",
        "100 pts\n",
        "\n",
        "## Goal \n",
        "\n",
        "The goal of this assignment \n",
        "\n",
        "*  Introduction to working with text data\n",
        "*  Gain experience with the Scikit-Learn library\n",
        "*  Gain experience with Naive Bayes and Logistic Regression\n",
        "\n",
        "## Dataset\n",
        "\n",
        "**20 Newsgroup Dataset** is a collection 18846 documents which are about 20 different topics.\n",
        "\n",
        "\n",
        "## Task\n",
        "Build naive bayes and logistic regression classifiers with the scikit-learn library function to **classify** the documents about their content topic.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Follow the instructions at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNnWi0hUEE_P"
      },
      "source": [
        "# 1) Initialize\n",
        "\n",
        "First, make a copy of this notebook in your drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JritpHX7EKdr"
      },
      "source": [
        "# 2) Load Dataset\n",
        "\n",
        "The 20 Newsgroup Dataset exist on Scikit-Learn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me2JuqB9EN3U"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zOI7YAhE2x3"
      },
      "source": [
        "train_batch = fetch_20newsgroups(subset='train')\n",
        "test_batch = fetch_20newsgroups(subset='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkSAOk1aKUzl",
        "outputId": "d38f005a-ada2-49ac-bbe3-5c6e0b57e5fc"
      },
      "source": [
        "# target groups you will be dealing with\n",
        "target_groups = train_batch.target_names\n",
        "target_groups"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 656
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEY5XoYmFVTr"
      },
      "source": [
        "# creating training and test sets\n",
        "train_x =  train_batch[\"data\"]\n",
        "train_y =  train_batch[\"target\"]\n",
        "test_x  =  test_batch[\"data\"]\n",
        "test_y  =  test_batch[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aiFqFY-Ftkc",
        "outputId": "c76a42a1-2682-42ae-cb1b-42310a2741ec"
      },
      "source": [
        "print(train_x[0])\n",
        "\n",
        "train_y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 658
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa_vTE97NsSL",
        "outputId": "1a00b1cf-a3e6-4ff3-cc59-f4ea452d3ba3"
      },
      "source": [
        "print(target_groups[train_y[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rec.autos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHJBZ6TFO6D6",
        "outputId": "5a76d049-b12d-4e6a-cdee-715bed8c02e6"
      },
      "source": [
        "print(len(train_x), len(test_x))\n",
        "print(len(train_y), len(test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11314 7532\n",
            "11314 7532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV4AaTk8JSPg"
      },
      "source": [
        "# Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZdKd6oAJWrj"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aukUdxk3JXft"
      },
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1oq7z0wJXdj"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldItHamFJwcO"
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YL6H0AQHwZl"
      },
      "source": [
        "# You will use this function to preprocess your data. If you would like to add another preprocessing step in the function, please add it and mention about it in your report.\n",
        "def preprocess(text):\n",
        "  text = re.sub(\"[\\w\\d._]+@[^\\s]+|[^\\s]+\\.[^\\s]+|[^\\s]+-[^\\s]+|\\d+|[^\\w\\s]\",\"\",text.lower().strip())\n",
        "  text = ' '.join([stemmer.stem(word) for word in re.findall(\"\\w+\",text) if word not in stop_words])\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL-jPAXPJffh"
      },
      "source": [
        "# Apply <preprocess> function on the training and test set \n",
        "preprocessed_train_x = [preprocess(sample) for sample in train_x]\n",
        "preprocessed_test_x = [preprocess(sample) for sample in test_x]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-tag1T6P0yT",
        "outputId": "960a234e-bea3-4c55-c069-de1f7f892589"
      },
      "source": [
        "print(preprocessed_train_x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "where thing subject car organ univers maryland colleg park line wonder anyon could enlighten car saw day sport car look late earli call bricklin door realli small addit front bumper separ rest bodi know anyon tellm model name engin spec year product car made histori whatev info funki look car pleas thank il brought neighborhood lerxst\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOFFQwnUOCCY"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yoKTkRCOFQh"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXJGT2HpNY8_"
      },
      "source": [
        "## Tune Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA5QFz37BoBc"
      },
      "source": [
        "# Create a CountVectorizer for NB with:\n",
        "min_df = 50\n",
        "max_df = 3000\n",
        "#     stop_words = stop_words\n",
        "vectorizerNaive = CountVectorizer(min_df=min_df, max_df=max_df,stop_words = stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS5WNNEhBxiZ"
      },
      "source": [
        "# Vectorize your training and test set\n",
        "train_x = vectorizerNaive.fit_transform(preprocessed_train_x)\n",
        "test_x = vectorizerNaive.transform(preprocessed_test_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVdPwcrsNymU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab912c59-8d1d-454f-f4b4-cbff7f6e11c7"
      },
      "source": [
        "#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "\n",
        "#Initiate the NB model with required components.\n",
        "mnb_pipeline = Pipeline([\n",
        "                         ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "\n",
        "#Set the hyperparameter space that will be scanned:\n",
        "hyperparameters = dict(\n",
        "    clf__alpha = (0.1,0.5,1.0,5.0),\n",
        ")\n",
        "\n",
        "\n",
        "#Let the GridSearchCV scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option.\n",
        "#   cv = 3\n",
        "#   scoring = \"accuracy\"\n",
        "\n",
        "mnb_grid_searchNaive = GridSearchCV(mnb_pipeline, hyperparameters, cv=3, scoring = 'accuracy', n_jobs=-1)\n",
        "mnb_grid_searchNaive.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('clf',\n",
              "                                        MultinomialNB(alpha=1.0,\n",
              "                                                      class_prior=None,\n",
              "                                                      fit_prior=True))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__alpha': (0.1, 0.5, 1.0, 5.0)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 671
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4xyqjD1N5Zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd64e984-a787-4287-f458-82e4684ec995"
      },
      "source": [
        "# show the best score\n",
        "mnb_grid_searchNaive.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8212835269890522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 672
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD888YxgO9d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9afc190-6326-4833-e166-fbf707ab5d6e"
      },
      "source": [
        "# show the best parameter\n",
        "mnb_grid_searchNaive.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 673
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJu_rA56W5jn"
      },
      "source": [
        "### Evaluate The Best Model for NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTTHdeA4O_kd"
      },
      "source": [
        "#Create your NB model with the best parameter set.\n",
        "modelNB = MultinomialNB(alpha=0.1)\n",
        "\n",
        "#Fit your model on training set.\n",
        "modelNB =modelNB.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unaw09TcXDGO"
      },
      "source": [
        "# Make predictions on test set\n",
        "predictions2 = modelNB.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIkAMwHKXEym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e08a7da-f9b6-4f6e-f6fe-978467783f80"
      },
      "source": [
        "# Show your accuracy on test set\n",
        "print(accuracy_score(test_y, predictions2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7535847052575677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJX62dPOXPdH"
      },
      "source": [
        "## Tune Logistic Regresion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1JQhjs3Cf2k"
      },
      "source": [
        "# Create a CountVectorizer for LR with:\n",
        "min_df = 50\n",
        "max_df = 3000\n",
        "stop_words = stop_words\n",
        "vectorizer = CountVectorizer(min_df=min_df, max_df=max_df,stop_words = stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTa3qQPCC0ts"
      },
      "source": [
        "# Vectorizer your training and test set\n",
        "train_xx = vectorizer.fit_transform(preprocessed_train_x)\n",
        "test_xx = vectorizer.transform(preprocessed_test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv2aolaqXF5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42548b83-e7ff-4a27-c753-1ca579eb16d9"
      },
      "source": [
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "#Initiate the LR model:\n",
        "max_iter=2000\n",
        "mnb_pipeline = Pipeline([\n",
        "                         ('Lr', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Set the hyperparameter space that will be scanned:\n",
        "#     C = (0.001,0.01,0.1,1)     1 OVER LAMDA\n",
        "hyperparameters = dict(\n",
        "    Lr__C = (0.001,0.01,0.1,1),\n",
        "    Lr__max_iter = (2000,),\n",
        ")\n",
        "\n",
        "#Let the GridSearchCV scan the hyperparameter and find the best hyperparameter set that will maximize the scoring option.\n",
        "#   cv = 3\n",
        "#   scoring = \"accuracy\"\n",
        "mnb_grid_search = GridSearchCV(mnb_pipeline, hyperparameters, cv=3, scoring = 'accuracy', n_jobs=-1)\n",
        "mnb_grid_search.fit(train_x,train_y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('Lr',\n",
              "                                        LogisticRegression(C=1.0,\n",
              "                                                           class_weight=None,\n",
              "                                                           dual=False,\n",
              "                                                           fit_intercept=True,\n",
              "                                                           intercept_scaling=1,\n",
              "                                                           l1_ratio=None,\n",
              "                                                           max_iter=100,\n",
              "                                                           multi_class='auto',\n",
              "                                                           n_jobs=None,\n",
              "                                                           penalty='l2',\n",
              "                                                           random_state=None,\n",
              "                                                           solver='lbfgs',\n",
              "                                                           tol=0.0001,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'Lr__C': (0.001, 0.01, 0.1, 1),\n",
              "                         'Lr__max_iter': (2000,)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 679
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhToPngFlsRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619edf92-cbdd-4c7a-9517-f1d6e7c3f45d"
      },
      "source": [
        "# show the best score\n",
        "mnb_grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8338344038554356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 680
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKQh_pyJl7cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb1b2c1-15a3-4340-a30e-328bbbce0702"
      },
      "source": [
        "# show the best parameter\n",
        "mnb_grid_search.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Lr__C': 0.1, 'Lr__max_iter': 2000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 681
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6n8TCfTbK8N"
      },
      "source": [
        "### Evaluate The Best Model for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIEOi8FEYcC8"
      },
      "source": [
        "#Create your LR model with the best parameter set.\n",
        "'''mnb_pipeline = Pipeline([\n",
        "                         ('Lr', LogisticRegression())\n",
        "]).set_params(**mnb_grid_search.best_params_)'''\n",
        "modelLR = LogisticRegression(C= 0.1, max_iter=2000)\n",
        "#Fit your model on training set.\n",
        "modelLR =modelLR.fit(train_x,train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u1ah0awbY4t"
      },
      "source": [
        "# Make predictions on test set\n",
        "predictions = model.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vH2DKHhbrPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18923ec-17c4-417a-f0b3-22d5a25a1509"
      },
      "source": [
        "# Show your accuracy on test set\n",
        "print(accuracy_score(test_y, predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7484067976633032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exoff4yjb7uI"
      },
      "source": [
        "# Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooLctLNhJoki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a99ae5-6983-40ae-e73b-f315f76821b9"
      },
      "source": [
        "# Find the each category's most important top 3 features (words) for LR model and show with a dataframe\n",
        "print(((modelLR.coef_)[0].shape),modelLR.coef_.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3099,) (20, 3099)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKIhmHNY-_mw",
        "outputId": "4db28b70-2b6b-42e4-ea8d-bd6c6a94081f"
      },
      "source": [
        "\n",
        "print(vectorizerNaive.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__', '___', '____', '_____', '_the', 'aa', 'aaron', 'ab', 'abc', 'abil', 'abl', 'abort', 'absolut', 'abstract', 'absurd', 'abus', 'ac', 'academ', 'acceler', 'accept', 'access', 'accid', 'accomplish', 'accord', 'account', 'accur', 'accuraci', 'accus', 'achiev', 'acid', 'acknowledg', 'acquir', 'across', 'act', 'action', 'activ', 'actual', 'ad', 'adam', 'adapt', 'add', 'addit', 'address', 'adequ', 'adjust', 'administr', 'admit', 'adob', 'adopt', 'adult', 'advanc', 'advantag', 'advertis', 'advic', 'advis', 'advoc', 'affair', 'affect', 'affili', 'afford', 'afraid', 'afterward', 'age', 'agenc', 'agenda', 'agent', 'aggress', 'ago', 'agre', 'agreement', 'ah', 'ahead', 'ai', 'aid', 'aim', 'aint', 'air', 'aka', 'al', 'ala', 'alan', 'albert', 'alberta', 'alcohol', 'alexand', 'algorithm', 'aliv', 'allan', 'alleg', 'allen', 'alloc', 'allow', 'almost', 'alon', 'along', 'alot', 'alreadi', 'also', 'alter', 'altern', 'although', 'alway', 'ama', 'amateur', 'amaz', 'ame', 'amend', 'america', 'american', 'amiga', 'among', 'amount', 'amp', 'amus', 'analog', 'analysi', 'ancient', 'anderson', 'andi', 'andor', 'andr', 'andrew', 'anecdot', 'angel', 'anger', 'angl', 'angri', 'anim', 'ann', 'announc', 'annoy', 'annual', 'anonym', 'anoth', 'answer', 'antenna', 'anybodi', 'anymor', 'anyon', 'anyth', 'anyway', 'anywher', 'apart', 'apollo', 'apolog', 'app', 'appar', 'appeal', 'appear', 'appl', 'appli', 'applic', 'appoint', 'appreci', 'appressian', 'approach', 'appropri', 'approv', 'approxim', 'apr', 'april', 'arab', 'arbitrari', 'arbor', 'architectur', 'archiv', 'area', 'arent', 'argic', 'argu', 'argument', 'aris', 'arizona', 'arm', 'armenia', 'armenian', 'armi', 'around', 'arrang', 'array', 'arrest', 'arriv', 'arrog', 'art', 'artifici', 'ascii', 'asid', 'ask', 'aspect', 'ass', 'assault', 'assembl', 'assert', 'assess', 'assign', 'assist', 'associ', 'assum', 'assumpt', 'assur', 'astronomi', 'atf', 'atheism', 'atheist', 'athen', 'ati', 'atlanta', 'atmospher', 'atom', 'att', 'attach', 'attack', 'attempt', 'attend', 'attent', 'attitud', 'attorney', 'attract', 'attribut', 'audio', 'august', 'austin', 'australia', 'authent', 'author', 'auto', 'automat', 'automobil', 'automot', 'avail', 'ave', 'avenu', 'averag', 'avoid', 'aw', 'awar', 'award', 'away', 'axe', 'babi', 'back', 'background', 'backup', 'bad', 'bag', 'balanc', 'ball', 'baltimor', 'ban', 'band', 'bandwidth', 'bank', 'bar', 'bare', 'barri', 'base', 'basebal', 'basi', 'basic', 'bat', 'batf', 'batteri', 'battl', 'bay', 'bbs', 'bc', 'beach', 'beam', 'bear', 'beast', 'beat', 'beauti', 'becam', 'becom', 'beer', 'beg', 'began', 'begin', 'behavior', 'behaviour', 'behind', 'belief', 'believ', 'bell', 'belong', 'ben', 'benefit', 'berkeley', 'besid', 'best', 'bet', 'beta', 'better', 'beyond', 'bias', 'bibl', 'biblic', 'big', 'bigger', 'biggest', 'bike', 'biker', 'bill', 'billion', 'binari', 'bio', 'biolog', 'birth', 'bit', 'bitmap', 'bitnet', 'black', 'blame', 'blank', 'blast', 'bless', 'blind', 'block', 'blood', 'blow', 'blown', 'blue', 'bmw', 'board', 'bob', 'bobbi', 'bodi', 'boe', 'bomb', 'bond', 'bone', 'book', 'boom', 'boot', 'border', 'bore', 'born', 'boston', 'bother', 'bottom', 'bought', 'boulder', 'bounc', 'bound', 'box', 'boy', 'brad', 'bradley', 'brain', 'brake', 'branch', 'brand', 'brave', 'break', 'breath', 'brent', 'brian', 'brief', 'bright', 'bring', 'britain', 'british', 'broad', 'broadcast', 'broke', 'broken', 'brook', 'brother', 'brought', 'brown', 'bruce', 'bruin', 'bryan', 'btw', 'buck', 'budget', 'buffalo', 'buffer', 'bug', 'build', 'built', 'bullet', 'bunch', 'burden', 'bureau', 'burn', 'bus', 'bush', 'busi', 'button', 'buy', 'buyer', 'byte', 'ca', 'cabl', 'cach', 'cage', 'cal', 'calcul', 'calgari', 'california', 'call', 'cambridg', 'came', 'camera', 'camp', 'campaign', 'campbel', 'campus', 'canada', 'canadian', 'cancer', 'candid', 'cannot', 'canon', 'cant', 'cap', 'capabl', 'capac', 'capit', 'captain', 'captur', 'car', 'card', 'cardin', 'care', 'career', 'carl', 'carnegi', 'carolina', 'carri', 'carter', 'case', 'cash', 'cast', 'cat', 'catalog', 'catch', 'categori', 'cathol', 'caught', 'caus', 'cb', 'cc', 'cd', 'ceas', 'celebr', 'cell', 'cellular', 'center', 'centr', 'central', 'centri', 'centuri', 'certain', 'chain', 'challeng', 'champ', 'champion', 'chanc', 'chang', 'channel', 'chapter', 'charact', 'character', 'characterist', 'charg', 'charl', 'charli', 'chastiti', 'cheap', 'cheaper', 'check', 'cheer', 'chemic', 'chemistri', 'chen', 'chicago', 'chief', 'child', 'children', 'chines', 'chip', 'choic', 'choos', 'chose', 'chosen', 'chris', 'christ', 'christian', 'christoph', 'chuck', 'church', 'circl', 'circuit', 'circumst', 'cite', 'citi', 'citizen', 'civil', 'civilian', 'claim', 'clark', 'class', 'classic', 'classifi', 'clayton', 'clean', 'clear', 'cleveland', 'click', 'client', 'clinic', 'clinton', 'clip', 'clipper', 'clock', 'clone', 'close', 'closer', 'cloth', 'cloud', 'club', 'clue', 'cnn', 'co', 'coach', 'coast', 'coat', 'code', 'cold', 'collaps', 'collect', 'colleg', 'collin', 'color', 'colorado', 'colour', 'columbia', 'column', 'combin', 'come', 'comfort', 'command', 'comment', 'commerci', 'commit', 'committe', 'common', 'communic', 'communiti', 'comp', 'compani', 'compar', 'comparison', 'compat', 'compel', 'compet', 'competit', 'compil', 'complain', 'complaint', 'complet', 'complex', 'complic', 'compon', 'compound', 'comprehens', 'compress', 'compromis', 'compuserv', 'comput', 'conceal', 'conceiv', 'concentr', 'concept', 'concern', 'conclud', 'conclus', 'condemn', 'condit', 'conduct', 'confer', 'confid', 'configur', 'confirm', 'conflict', 'confus', 'congress', 'connect', 'connector', 'conscious', 'consent', 'consequ', 'conserv', 'consid', 'consider', 'consist', 'conspiraci', 'constant', 'constitut', 'construct', 'consult', 'consum', 'contact', 'contain', 'content', 'context', 'continu', 'contract', 'contradict', 'contrari', 'contrast', 'contribut', 'control', 'conveni', 'convent', 'convers', 'convert', 'convict', 'convinc', 'cook', 'cool', 'cooper', 'coordin', 'cop', 'copi', 'copyright', 'core', 'corner', 'corp', 'corpor', 'correct', 'correspond', 'corrupt', 'cost', 'could', 'couldnt', 'council', 'count', 'counter', 'counti', 'countri', 'coupl', 'cours', 'court', 'cover', 'coverag', 'covington', 'cpu', 'crack', 'craig', 'cramer', 'crap', 'crash', 'crazi', 'creat', 'creation', 'creativ', 'credit', 'crew', 'cri', 'crime', 'crimin', 'critic', 'cross', 'crowd', 'crypto', 'cryptographi', 'cs', 'ct', 'cub', 'cult', 'cultur', 'cup', 'cure', 'curious', 'current', 'custom', 'cut', 'cycl', 'cylind', 'daili', 'dale', 'dalla', 'damag', 'damn', 'dan', 'danc', 'danger', 'daniel', 'danni', 'dare', 'dark', 'data', 'databas', 'date', 'daughter', 'dave', 'davi', 'david', 'davidian', 'day', 'dc', 'de', 'dead', 'deal', 'dealer', 'dean', 'dear', 'death', 'debat', 'dec', 'decad', 'decemb', 'decent', 'decid', 'decis', 'declar', 'declin', 'decod', 'decreas', 'decrypt', 'dedic', 'deed', 'deep', 'default', 'defend', 'defens', 'defin', 'definit', 'degre', 'delawar', 'delay', 'delet', 'deliber', 'deliv', 'demand', 'demo', 'democraci', 'democrat', 'demonstr', 'den', 'deni', 'denni', 'denver', 'depart', 'depend', 'depress', 'dept', 'depth', 'der', 'deriv', 'des', 'describ', 'descript', 'deserv', 'design', 'desir', 'desk', 'desktop', 'despit', 'destroy', 'destruct', 'detail', 'detect', 'detector', 'determin', 'detroit', 'develop', 'devic', 'devil', 'devot', 'diagnos', 'diamond', 'dick', 'dictat', 'dictionari', 'didnt', 'die', 'diego', 'diet', 'differ', 'differenti', 'difficult', 'difficulti', 'digest', 'digit', 'dimens', 'direct', 'director', 'directori', 'dirti', 'disabl', 'disagre', 'disappear', 'disappoint', 'disclaim', 'discov', 'discrimin', 'discuss', 'diseas', 'disk', 'display', 'disput', 'disregard', 'distanc', 'distinct', 'distinguish', 'distort', 'distribut', 'district', 'disturb', 'div', 'divid', 'dividian', 'divin', 'divis', 'doc', 'doctor', 'doctrin', 'document', 'dod', 'doesnt', 'dog', 'dollar', 'domain', 'domin', 'donald', 'done', 'door', 'dos', 'doubl', 'doubt', 'doug', 'dougla', 'download', 'dozen', 'dr', 'draft', 'drag', 'draw', 'drawn', 'dream', 'dri', 'drink', 'drive', 'driven', 'driver', 'drop', 'drove', 'drug', 'dual', 'due', 'dumb', 'dump', 'dust', 'duti', 'dx', 'dynam', 'ear', 'earl', 'earli', 'earlier', 'earn', 'earth', 'easi', 'easier', 'easili', 'east', 'eastern', 'eat', 'echo', 'econom', 'economi', 'ed', 'edg', 'edit', 'editor', 'edmonton', 'educ', 'edward', 'eff', 'effect', 'effici', 'effort', 'eg', 'eh', 'eight', 'einstein', 'either', 'elect', 'electr', 'electron', 'element', 'elev', 'elimin', 'els', 'elsewher', 'em', 'email', 'emerg', 'emot', 'emphas', 'emphasi', 'empir', 'employ', 'employe', 'empti', 'emul', 'enabl', 'encount', 'encourag', 'encrypt', 'end', 'endors', 'enemi', 'energi', 'enforc', 'engag', 'engin', 'england', 'english', 'enhanc', 'enjoy', 'enlighten', 'enough', 'ensur', 'enter', 'entertain', 'entir', 'entiti', 'entitl', 'entri', 'environ', 'environment', 'equal', 'equat', 'equip', 'equival', 'era', 'eric', 'error', 'escap', 'escrow', 'especi', 'espn', 'essenti', 'establish', 'estim', 'et', 'etc', 'etern', 'ethernet', 'ethic', 'ethnic', 'europ', 'european', 'evalu', 'evan', 'even', 'event', 'eventu', 'ever', 'everi', 'everybodi', 'everyon', 'everyth', 'everywher', 'evid', 'evil', 'ex', 'exact', 'examin', 'exampl', 'exceed', 'excel', 'except', 'excess', 'exchang', 'excit', 'exclud', 'exclus', 'excus', 'execut', 'exercis', 'exhaust', 'exhibit', 'exist', 'exit', 'expand', 'expans', 'expect', 'expens', 'experi', 'experienc', 'experiment', 'expert', 'expir', 'explain', 'explan', 'explicit', 'explor', 'explos', 'export', 'expos', 'exposur', 'express', 'extend', 'extens', 'extent', 'extermin', 'extern', 'extra', 'extract', 'extrem', 'eye', 'face', 'facil', 'fact', 'factor', 'factori', 'fail', 'failur', 'fair', 'faith', 'fall', 'fals', 'famili', 'familiar', 'famous', 'fan', 'fanat', 'fanci', 'faq', 'far', 'farm', 'fascist', 'fashion', 'fast', 'faster', 'fatal', 'father', 'fault', 'favor', 'favorit', 'fax', 'fbi', 'fear', 'featur', 'feb', 'februari', 'fed', 'feder', 'fee', 'feed', 'feel', 'feet', 'fell', 'fellow', 'felt', 'femal', 'fewer', 'fiction', 'field', 'fifth', 'fight', 'figur', 'file', 'fill', 'film', 'filter', 'final', 'financi', 'find', 'fine', 'finger', 'finish', 'finland', 'fire', 'firearm', 'firm', 'first', 'fischer', 'fish', 'fit', 'five', 'fix', 'flag', 'flame', 'flash', 'flat', 'flaw', 'fli', 'flight', 'floor', 'floppi', 'florida', 'flow', 'flyer', 'focus', 'folk', 'follow', 'followup', 'font', 'food', 'fool', 'foot', 'forc', 'ford', 'foreign', 'forev', 'forget', 'forgiv', 'forgot', 'form', 'formal', 'format', 'former', 'forsal', 'fort', 'forth', 'fortun', 'forum', 'forward', 'found', 'foundat', 'four', 'fourth', 'frame', 'franc', 'franci', 'francisco', 'frank', 'fred', 'free', 'freedom', 'freeli', 'freeman', 'french', 'frequenc', 'frequent', 'fresh', 'fri', 'friday', 'friend', 'front', 'frustrat', 'ftp', 'fuck', 'fuel', 'fulfil', 'full', 'fulli', 'fun', 'function', 'fund', 'fundament', 'funni', 'furthermor', 'futur', 'gain', 'game', 'gang', 'garag', 'garbag', 'gari', 'gas', 'gate', 'gateway', 'gather', 'gave', 'gay', 'gear', 'gee', 'gene', 'general', 'generat', 'genocid', 'georg', 'georgia', 'gerald', 'german', 'germani', 'giant', 'gif', 'gift', 'girl', 'give', 'given', 'glad', 'glass', 'global', 'gm', 'gmt', 'go', 'goal', 'goali', 'god', 'goe', 'gold', 'golden', 'gone', 'gonna', 'good', 'gordon', 'gospel', 'got', 'gotta', 'gotten', 'govern', 'govt', 'grab', 'grace', 'grade', 'graduat', 'graham', 'grand', 'grant', 'graphic', 'grave', 'graviti', 'great', 'greater', 'greatest', 'greek', 'green', 'greenbelt', 'greet', 'greg', 'gregg', 'gregori', 'ground', 'group', 'grow', 'growth', 'gt', 'guarante', 'guard', 'guess', 'guest', 'guid', 'guilti', 'gun', 'gut', 'guy', 'habit', 'hacker', 'hair', 'half', 'hall', 'hand', 'handgun', 'handi', 'handl', 'hang', 'happen', 'happi', 'hard', 'harder', 'hardwar', 'harm', 'harri', 'harvard', 'harvey', 'hasnt', 'hat', 'hate', 'hatr', 'havent', 'hawk', 'hd', 'head', 'header', 'health', 'healthi', 'hear', 'heard', 'heart', 'heat', 'heaven', 'heavi', 'hebrew', 'heck', 'hed', 'height', 'held', 'hell', 'hello', 'helmet', 'help', 'henc', 'henri', 'hes', 'hey', 'hi', 'hidden', 'hide', 'high', 'higher', 'highest', 'highway', 'hill', 'hint', 'hire', 'histor', 'histori', 'hit', 'hitler', 'hitter', 'hmm', 'hmmm', 'hockey', 'hold', 'hole', 'holi', 'holland', 'holocaust', 'home', 'homosexu', 'honda', 'honest', 'honor', 'hook', 'hope', 'hopkin', 'horizont', 'horn', 'horribl', 'hors', 'hospit', 'host', 'hostil', 'hot', 'hour', 'hous', 'houston', 'howard', 'howev', 'hp', 'hr', 'huge', 'hugh', 'huh', 'human', 'humor', 'hundr', 'hunt', 'hurt', 'husband', 'ia', 'ian', 'ibm', 'ic', 'ice', 'icon', 'id', 'ide', 'idea', 'ideal', 'ident', 'identifi', 'ideolog', 'idiot', 'ie', 'ignor', 'ii', 'iii', 'il', 'ill', 'illeg', 'illinoi', 'illustr', 'im', 'imag', 'imagin', 'imho', 'immedi', 'immor', 'imo', 'impact', 'implement', 'impli', 'implic', 'import', 'impos', 'imposs', 'impress', 'improv', 'inc', 'inch', 'incid', 'inclin', 'includ', 'incom', 'incompat', 'incorpor', 'incorrect', 'increas', 'incred', 'inde', 'independ', 'index', 'indian', 'indiana', 'indic', 'individu', 'industri', 'inet', 'inevit', 'inexpens', 'infect', 'infinit', 'inflat', 'influenc', 'info', 'inform', 'infrastructur', 'inhabit', 'inher', 'initi', 'inject', 'injur', 'injuri', 'inning', 'innoc', 'input', 'insert', 'insid', 'insight', 'insist', 'inspir', 'instal', 'instanc', 'instead', 'institut', 'instruct', 'instrument', 'insult', 'insur', 'int', 'integr', 'intel', 'intellect', 'intellectu', 'intellig', 'intend', 'intens', 'intent', 'interact', 'interest', 'interfac', 'interfer', 'intern', 'internet', 'interpret', 'interrupt', 'interview', 'introduc', 'introduct', 'invad', 'invas', 'invent', 'invest', 'investig', 'invit', 'invok', 'involv', 'io', 'iowa', 'iron', 'irrelev', 'irvin', 'isa', 'islam', 'island', 'isnt', 'isol', 'isra', 'israel', 'issu', 'item', 'itll', 'iv', 'ive', 'jack', 'jackson', 'jame', 'jan', 'januari', 'japan', 'japanes', 'jason', 'jay', 'jeff', 'jerri', 'jersey', 'jerusalem', 'jesus', 'jet', 'jew', 'jewish', 'jim', 'jimmi', 'job', 'joe', 'joel', 'john', 'johnson', 'join', 'joint', 'joke', 'jon', 'jonathan', 'jone', 'jordan', 'jose', 'joseph', 'josh', 'journal', 'jr', 'judg', 'judgement', 'juli', 'jump', 'jumper', 'june', 'junk', 'justic', 'justif', 'justifi', 'kansa', 'keep', 'keith', 'ken', 'kenneth', 'kent', 'kept', 'kevin', 'key', 'keyboard', 'keyword', 'kick', 'kid', 'kill', 'kind', 'kinda', 'king', 'kingdom', 'kit', 'knew', 'knock', 'knowledg', 'known', 'koresh', 'la', 'lab', 'label', 'laboratori', 'lack', 'ladi', 'lake', 'land', 'lane', 'languag', 'larg', 'larger', 'largest', 'larri', 'laser', 'last', 'late', 'later', 'latest', 'latter', 'laugh', 'launch', 'law', 'lawrenc', 'lawyer', 'lay', 'layer', 'lc', 'le', 'lead', 'leader', 'leadership', 'leaf', 'leagu', 'lean', 'learn', 'least', 'leav', 'lebanes', 'lebanon', 'led', 'lee', 'left', 'leg', 'legal', 'legisl', 'legitim', 'length', 'less', 'lesson', 'let', 'letter', 'level', 'lewi', 'liabil', 'liber', 'libertarian', 'liberti', 'librari', 'licens', 'lie', 'life', 'lifetim', 'lift', 'light', 'limit', 'link', 'linux', 'list', 'listen', 'liter', 'literatur', 'littl', 'live', 'livesey', 'load', 'local', 'locat', 'lock', 'log', 'logic', 'login', 'london', 'long', 'longer', 'look', 'loop', 'loos', 'lord', 'los', 'lose', 'loss', 'lost', 'lot', 'loud', 'loui', 'love', 'low', 'lower', 'ltd', 'luck', 'lucki', 'lunar', 'lunch', 'mac', 'machin', 'macintosh', 'mad', 'made', 'mag', 'magazin', 'magic', 'mail', 'main', 'maintain', 'major', 'make', 'male', 'man', 'manag', 'mani', 'manipul', 'manner', 'manual', 'manufactur', 'map', 'mapl', 'mar', 'marc', 'march', 'margin', 'mari', 'marin', 'mark', 'market', 'marri', 'marriag', 'martin', 'maryland', 'mask', 'mass', 'massachusett', 'massacr', 'massiv', 'master', 'mat', 'match', 'materi', 'math', 'mathemat', 'mathew', 'matt', 'matter', 'matthew', 'max', 'maximum', 'may', 'mayb', 'maynard', 'mb', 'md', 'mean', 'meant', 'measur', 'mechan', 'media', 'medic', 'medicin', 'meet', 'meg', 'melkonian', 'mellon', 'member', 'membership', 'memori', 'men', 'mental', 'mention', 'menu', 'merci', 'mere', 'merit', 'mess', 'messag', 'met', 'metal', 'meter', 'method', 'methodolog', 'mexico', 'mhz', 'mi', 'michael', 'michigan', 'microsoft', 'microsystem', 'middl', 'might', 'mike', 'mile', 'mileag', 'militari', 'miller', 'million', 'milwauke', 'mind', 'mine', 'minim', 'minimum', 'minist', 'ministri', 'minnesota', 'minor', 'minut', 'miracl', 'mirror', 'miss', 'mission', 'mistak', 'mistaken', 'mit', 'mix', 'mm', 'mo', 'mobil', 'mode', 'model', 'modem', 'moder', 'modern', 'modifi', 'modul', 'moment', 'mon', 'monday', 'money', 'monitor', 'month', 'montreal', 'moon', 'moral', 'morn', 'morri', 'mother', 'motherboard', 'motif', 'motion', 'motiv', 'motor', 'motorcycl', 'motorola', 'mount', 'mountain', 'mous', 'mouth', 'move', 'movement', 'movi', 'mph', 'mr', 'ms', 'msg', 'much', 'multipl', 'murder', 'murray', 'muscl', 'music', 'muslim', 'must', 'mutual', 'mysteri', 'na', 'name', 'narrow', 'nasa', 'nasti', 'nation', 'nativ', 'natur', 'nazi', 'nc', 'nd', 'near', 'nearbi', 'neat', 'nec', 'necessari', 'necessarili', 'need', 'negat', 'negoti', 'neighbor', 'neil', 'neither', 'net', 'netcom', 'netherland', 'netter', 'network', 'neutral', 'never', 'nevertheless', 'new', 'newer', 'news', 'newsgroup', 'newspap', 'next', 'nh', 'nhl', 'nice', 'nichol', 'nick', 'night', 'nine', 'nj', 'njxp', 'nl', 'nobodi', 'nois', 'non', 'none', 'nonsens', 'nope', 'normal', 'norman', 'north', 'northern', 'norton', 'nose', 'note', 'noth', 'notic', 'notion', 'novel', 'novemb', 'nowher', 'nra', 'ns', 'nsa', 'nt', 'nuclear', 'number', 'numer', 'nuntius', 'nut', 'ny', 'nyc', 'oakland', 'obey', 'object', 'oblig', 'obscur', 'observ', 'obtain', 'obvious', 'occas', 'occasion', 'occup', 'occupi', 'occur', 'octob', 'odd', 'offend', 'offens', 'offer', 'offic', 'offici', 'often', 'oh', 'ohanus', 'ohio', 'oil', 'ok', 'okay', 'olchowi', 'old', 'older', 'onlin', 'ontario', 'onto', 'open', 'openwindow', 'oper', 'opinion', 'oppon', 'opportun', 'oppos', 'opposit', 'optim', 'option', 'orbit', 'order', 'ordinari', 'oregon', 'orient', 'origin', 'os', 'otherwis', 'ottawa', 'ought', 'outlaw', 'outlin', 'output', 'outsid', 'overal', 'overwhelm', 'owner', 'ownership', 'pa', 'pacif', 'pack', 'packag', 'pad', 'page', 'paid', 'pain', 'paint', 'pair', 'palestin', 'palestinian', 'panel', 'paper', 'paragraph', 'parallel', 'paramet', 'parent', 'park', 'part', 'parti', 'partial', 'particip', 'particular', 'partner', 'pasadena', 'pass', 'passag', 'passeng', 'past', 'pat', 'patch', 'patent', 'path', 'patient', 'patrick', 'pattern', 'paul', 'pay', 'pc', 'pcs', 'peac', 'pen', 'penalti', 'penguin', 'penn', 'pennsylvania', 'peopl', 'per', 'perceiv', 'percent', 'percentag', 'perfect', 'perform', 'perhap', 'period', 'perman', 'permiss', 'permit', 'perri', 'persecut', 'person', 'perspect', 'pete', 'peter', 'pgp', 'phase', 'phil', 'philadelphia', 'philip', 'philli', 'philosoph', 'philosophi', 'phone', 'photo', 'phrase', 'physic', 'physician', 'pick', 'pictur', 'piec', 'pin', 'pipe', 'piss', 'pitch', 'pitcher', 'pittsburgh', 'pixel', 'pl', 'place', 'plain', 'plan', 'plane', 'planet', 'planetari', 'plant', 'plastic', 'plate', 'platform', 'play', 'player', 'playoff', 'pleas', 'plenti', 'plot', 'plug', 'plus', 'pm', 'po', 'pocket', 'point', 'pointer', 'polic', 'polici', 'polit', 'politician', 'poll', 'polytechn', 'pool', 'poor', 'pop', 'pope', 'popul', 'popular', 'port', 'portabl', 'portion', 'pose', 'posit', 'possess', 'possibl', 'post', 'poster', 'postscript', 'potenti', 'pound', 'power', 'powerbook', 'pp', 'practic', 'pray', 'prayer', 'preach', 'preced', 'precis', 'predict', 'prefer', 'prepar', 'presenc', 'present', 'preserv', 'presid', 'press', 'pressur', 'presum', 'pretti', 'prevent', 'previous', 'price', 'priest', 'primari', 'primarili', 'prime', 'princeton', 'principl', 'print', 'printer', 'prior', 'prison', 'privaci', 'privat', 'prize', 'pro', 'probabl', 'probe', 'problem', 'procedur', 'proceed', 'process', 'processor', 'proclaim', 'produc', 'product', 'profession', 'professor', 'profit', 'program', 'programm', 'progress', 'prohibit', 'project', 'promis', 'promot', 'prompt', 'proof', 'propaganda', 'proper', 'properti', 'prophet', 'propos', 'propuls', 'prospect', 'protect', 'protest', 'protocol', 'proud', 'prove', 'proven', 'provid', 'ps', 'psycholog', 'public', 'publish', 'pull', 'pump', 'punish', 'purchas', 'purdu', 'pure', 'purpos', 'pursu', 'push', 'put', 'qas', 'quadra', 'qualifi', 'qualiti', 'quantiti', 'quantum', 'quarter', 'quebec', 'queri', 'question', 'quick', 'quiet', 'quit', 'quot', 'race', 'radar', 'radiat', 'radic', 'radio', 'raid', 'rain', 'rais', 'ralph', 'ram', 'ran', 'ranch', 'randi', 'random', 'rang', 'ranger', 'rank', 'rape', 'rapid', 'rare', 'rate', 'rather', 'ratio', 'ration', 'raw', 'ray', 'rc', 'rd', 'reach', 'react', 'reaction', 'read', 'reader', 'readi', 'real', 'realiti', 'realiz', 'realli', 'rear', 'reason', 'recal', 'receiv', 'recent', 'recogn', 'recommend', 'record', 'recov', 'red', 'reduc', 'refer', 'reflect', 'reform', 'refus', 'regard', 'regardless', 'region', 'regist', 'registr', 'regul', 'regular', 'reject', 'relat', 'relationship', 'releas', 'relev', 'reli', 'reliabl', 'relief', 'religi', 'religion', 'remain', 'remark', 'rememb', 'remind', 'remot', 'remov', 'render', 'rent', 'rep', 'repair', 'repeat', 'replac', 'repli', 'report', 'repost', 'repres', 'republ', 'republican', 'reput', 'request', 'requir', 'research', 'reserv', 'reset', 'resid', 'resist', 'resolut', 'resolv', 'resort', 'resourc', 'respect', 'respond', 'respons', 'rest', 'restor', 'restrict', 'result', 'resurrect', 'retir', 'return', 'rev', 'reveal', 'revel', 'revers', 'review', 'revis', 'revolut', 'reward', 'rf', 'rice', 'rich', 'richard', 'richardson', 'rick', 'rid', 'ride', 'rider', 'ridicul', 'rifl', 'right', 'ring', 'rip', 'rise', 'risk', 'river', 'rm', 'road', 'rob', 'robert', 'rochest', 'rock', 'rocket', 'roger', 'role', 'roll', 'rom', 'roman', 'ron', 'room', 'root', 'rose', 'rotat', 'rough', 'round', 'rout', 'routin', 'row', 'roy', 'royal', 'rs', 'ruin', 'rule', 'rumor', 'run', 'rush', 'russel', 'russia', 'russian', 'ryan', 'sacrific', 'sad', 'safe', 'safeti', 'sahak', 'said', 'saint', 'sake', 'sale', 'salt', 'salvat', 'sam', 'sampl', 'san', 'sandvik', 'santa', 'sat', 'satan', 'satellit', 'satisfi', 'saturday', 'save', 'saw', 'say', 'sc', 'scale', 'scan', 'scanner', 'scare', 'scene', 'schedul', 'scheme', 'schneider', 'scholar', 'school', 'sci', 'scienc', 'scientif', 'scientist', 'scope', 'score', 'scott', 'scratch', 'screen', 'screw', 'scriptur', 'scsi', 'se', 'sea', 'seal', 'sean', 'search', 'season', 'seat', 'seattl', 'second', 'secret', 'secretari', 'section', 'sector', 'secur', 'see', 'seed', 'seek', 'seem', 'seen', 'segment', 'selann', 'select', 'self', 'sell', 'senat', 'send', 'senior', 'sens', 'sensit', 'sensor', 'sent', 'sentenc', 'separ', 'seper', 'sequenc', 'serdar', 'seri', 'serial', 'serious', 'serv', 'server', 'servic', 'session', 'set', 'settl', 'setup', 'seven', 'sever', 'sex', 'sexual', 'sgi', 'shadow', 'shaft', 'shall', 'shame', 'shape', 'share', 'sharewar', 'shed', 'sheet', 'shelf', 'shell', 'shield', 'shift', 'ship', 'shit', 'shock', 'shoot', 'shop', 'short', 'shot', 'shoulder', 'shouldnt', 'show', 'shown', 'shut', 'shuttl', 'si', 'sick', 'side', 'sig', 'sight', 'sign', 'signal', 'signatur', 'signific', 'silenc', 'silent', 'silicon', 'silli', 'silver', 'similar', 'simm', 'simon', 'simpl', 'simpli', 'simul', 'sin', 'sinc', 'sincer', 'singl', 'sir', 'sit', 'site', 'situat', 'six', 'size', 'skeptic', 'skill', 'skin', 'sky', 'slaughter', 'slave', 'sleep', 'slide', 'slight', 'slot', 'slow', 'slower', 'small', 'smaller', 'smart', 'smith', 'smoke', 'snow', 'social', 'societi', 'socket', 'soft', 'softwar', 'solar', 'sold', 'soldier', 'sole', 'solid', 'solut', 'solv', 'somebodi', 'somehow', 'someon', 'someth', 'sometim', 'somewhat', 'somewher', 'son', 'soni', 'soon', 'sorri', 'sort', 'soul', 'sound', 'sourc', 'south', 'southern', 'soviet', 'sp', 'space', 'spacecraft', 'sparc', 'spare', 'speak', 'speaker', 'spec', 'speci', 'special', 'specif', 'specifi', 'spectrum', 'specul', 'speech', 'speed', 'spell', 'spencer', 'spend', 'spent', 'spin', 'spirit', 'spiritu', 'split', 'spoke', 'sponsor', 'sport', 'spot', 'spread', 'spring', 'squar', 'ss', 'st', 'stabl', 'stack', 'staff', 'stage', 'stan', 'stand', 'standard', 'stanford', 'stanley', 'star', 'start', 'starter', 'startup', 'stat', 'state', 'statement', 'station', 'statist', 'status', 'stay', 'steal', 'stealth', 'steel', 'steer', 'step', 'stephen', 'stereo', 'sternlight', 'steve', 'steven', 'stick', 'still', 'stock', 'stolen', 'stone', 'stood', 'stop', 'storag', 'store', 'stori', 'storm', 'straight', 'strang', 'strategi', 'stream', 'street', 'strength', 'stress', 'stretch', 'strict', 'strike', 'string', 'strip', 'strong', 'stronger', 'struck', 'structur', 'struggl', 'stuck', 'student', 'studi', 'stuff', 'stupid', 'style', 'submit', 'subscrib', 'subsequ', 'substanc', 'substanti', 'substitut', 'succeed', 'success', 'suck', 'sudden', 'suffer', 'suffici', 'suggest', 'suicid', 'suit', 'suitabl', 'sum', 'summar', 'summari', 'summer', 'sun', 'sunday', 'suno', 'super', 'superior', 'superstit', 'suppli', 'support', 'suppos', 'suprem', 'sure', 'surfac', 'surpris', 'surrend', 'surround', 'survey', 'surviv', 'survivor', 'suspect', 'svga', 'sw', 'swap', 'sweden', 'sweep', 'switch', 'sx', 'symbol', 'symptom', 'syndrom', 'system', 'tabl', 'tactic', 'tail', 'take', 'taken', 'talent', 'talk', 'tank', 'tap', 'tape', 'target', 'task', 'tast', 'taught', 'tavar', 'tax', 'taylor', 'teach', 'teacher', 'team', 'tear', 'tech', 'technic', 'techniqu', 'technolog', 'ted', 'tektronix', 'tel', 'telecom', 'telephon', 'telescop', 'televis', 'tell', 'temperatur', 'temporari', 'ten', 'tend', 'term', 'termin', 'terri', 'terribl', 'territori', 'terror', 'terrorist', 'test', 'testament', 'testimoni', 'texa', 'text', 'th', 'thank', 'thanx', 'theist', 'theodor', 'theolog', 'theoret', 'theori', 'therefor', 'theyd', 'theyll', 'theyr', 'theyv', 'thing', 'think', 'third', 'thoma', 'thorough', 'though', 'thought', 'thousand', 'thread', 'threat', 'threaten', 'three', 'threw', 'throughout', 'throw', 'thrown', 'thru', 'thu', 'thumb', 'thursday', 'thus', 'ticket', 'tie', 'tiger', 'tight', 'till', 'tim', 'time', 'timothi', 'tin', 'tini', 'tip', 'tire', 'titl', 'tm', 'toal', 'today', 'todd', 'togeth', 'told', 'toler', 'tom', 'tommi', 'tomorrow', 'ton', 'toni', 'tonight', 'took', 'tool', 'toolkit', 'top', 'topic', 'toronto', 'tortur', 'total', 'touch', 'tough', 'toward', 'tower', 'town', 'toyota', 'trace', 'track', 'trade', 'tradit', 'traffic', 'train', 'transfer', 'transform', 'translat', 'transmiss', 'transmit', 'transport', 'trap', 'trash', 'travel', 'treat', 'treatment', 'tree', 'trend', 'tri', 'trial', 'trick', 'trip', 'trivial', 'troop', 'troubl', 'truck', 'true', 'truli', 'trust', 'truth', 'tube', 'tue', 'tuesday', 'tune', 'turbo', 'turk', 'turkey', 'turkish', 'turn', 'tv', 'twice', 'twin', 'twist', 'two', 'tx', 'type', 'typic', 'uh', 'uk', 'ultim', 'ultra', 'unabl', 'understand', 'understood', 'unfortun', 'uniform', 'union', 'uniqu', 'unit', 'univ', 'unix', 'unknown', 'unless', 'unlik', 'unusu', 'updat', 'upgrad', 'upon', 'upper', 'upset', 'urbana', 'us', 'usa', 'usag', 'useless', 'usenet', 'user', 'usual', 'util', 'utter', 'uucp', 'va', 'valid', 'valley', 'valu', 'valuabl', 'van', 'vancouv', 'vari', 'variabl', 'varieti', 'various', 'vast', 'vaxvm', 'vehicl', 'vendor', 'verifi', 'vers', 'version', 'versus', 'vertic', 'vesa', 'vga', 'via', 'vice', 'victim', 'victori', 'video', 'view', 'villag', 'violat', 'violenc', 'violent', 'virginia', 'virtual', 'virus', 'visibl', 'vision', 'visit', 'visual', 'vlb', 'vms', 'vnew', 'voic', 'void', 'vol', 'voltag', 'volum', 'volunt', 'vote', 'vram', 'vs', 'wa', 'waco', 'wait', 'wake', 'walk', 'walker', 'wall', 'walter', 'want', 'war', 'warm', 'warn', 'warrant', 'warranti', 'wash', 'washington', 'wasnt', 'wast', 'watch', 'water', 'waterloo', 'watt', 'wave', 'way', 'wayn', 'weak', 'weapon', 'wear', 'weather', 'wed', 'wednesday', 'week', 'weekend', 'weight', 'weird', 'welcom', 'well', 'went', 'werent', 'west', 'western', 'weve', 'whatev', 'whatsoev', 'wheel', 'whenev', 'wherea', 'whether', 'white', 'whoever', 'whole', 'whos', 'whose', 'wide', 'widespread', 'widget', 'wife', 'wild', 'willi', 'william', 'wilson', 'win', 'wind', 'window', 'wing', 'winner', 'winnipeg', 'winter', 'wire', 'wiretap', 'wisconsin', 'wisdom', 'wise', 'wish', 'wit', 'within', 'without', 'woman', 'women', 'wonder', 'wont', 'wood', 'word', 'work', 'worker', 'workstat', 'world', 'worri', 'wors', 'worship', 'worst', 'worth', 'worthi', 'worthless', 'wouldnt', 'wound', 'wow', 'wrap', 'wright', 'writer', 'written', 'wrong', 'wrote', 'xlib', 'xr', 'xt', 'xterm', 'xx', 'ya', 'yanke', 'yeah', 'year', 'yes', 'yesterday', 'yet', 'york', 'youd', 'youll', 'young', 'youv', 'zealand', 'zero', 'zone']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joZ99WFPemHV",
        "outputId": "5948f330-d76b-43cf-90b9-07b40acd8066"
      },
      "source": [
        "Feature_names = vectorizer.get_feature_names()\n",
        "featureList = []\n",
        "for i in range(len(target_groups)):\n",
        "  top3 = np.argsort(np.abs(modelLR.coef_[i]))[len(modelLR.coef_[i])-3:len(modelLR.coef_[i])]\n",
        "  reversedTop3 = top3[::-1]\n",
        "  print(reversedTop3)\n",
        "  TargetFeatures = []\n",
        "  for j in reversedTop3:\n",
        "    TargetFeatures.append(Feature_names[j])\n",
        "  featureList.append(TargetFeatures)\n",
        "print(featureList)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 203 1533 1474]\n",
            "[1219 1374  127]\n",
            "[3039 3037  848]\n",
            "[1791 1169 1799]\n",
            "[1659  149 2102]\n",
            "[3080 3031 1800]\n",
            "[2379 1921 1119]\n",
            "[422 228 225]\n",
            "[ 822  300 1804]\n",
            "[ 256 2035 3085]\n",
            "[1312 2739 2066]\n",
            "[ 515  913 2728]\n",
            "[ 494  893 2883]\n",
            "[ 819  801 1721]\n",
            "[2574 1947 1995]\n",
            "[ 489  810 1198]\n",
            "[1243 2977 1080]\n",
            "[1479 1478 2453]\n",
            "[2773  513 1611]\n",
            "[ 489 1948 1554]\n",
            "[['atheist', 'keith', 'islam'], ['graphic', 'imag', 'anim'], ['window', 'win', 'driver'], ['monitor', 'gateway', 'motherboard'], ['mac', 'appl', 'powerbook'], ['xr', 'widget', 'motif'], ['sale', 'offer', 'forsal'], ['car', 'automot', 'auto'], ['dod', 'bike', 'motorcycl'], ['basebal', 'philli', 'yanke'], ['hockey', 'team', 'playoff'], ['clipper', 'encrypt', 'tap'], ['circuit', 'electron', 'tv'], ['doctor', 'diseas', 'medic'], ['space', 'orbit', 'pat'], ['christian', 'distribut', 'god'], ['gun', 'waco', 'firearm'], ['israel', 'isra', 'serdar'], ['theodor', 'clinton', 'libertarian'], ['christian', 'order', 'koresh']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "imPK4RO2hIQF",
        "outputId": "150b5055-6fa0-419d-c478-a9976c6df3a4"
      },
      "source": [
        "Df = pd.DataFrame(featureList, index=target_groups)\n",
        "Df.head(20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt.atheism</th>\n",
              "      <td>atheist</td>\n",
              "      <td>keith</td>\n",
              "      <td>islam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.graphics</th>\n",
              "      <td>graphic</td>\n",
              "      <td>imag</td>\n",
              "      <td>anim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.os.ms-windows.misc</th>\n",
              "      <td>window</td>\n",
              "      <td>win</td>\n",
              "      <td>driver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.sys.ibm.pc.hardware</th>\n",
              "      <td>monitor</td>\n",
              "      <td>gateway</td>\n",
              "      <td>motherboard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.sys.mac.hardware</th>\n",
              "      <td>mac</td>\n",
              "      <td>appl</td>\n",
              "      <td>powerbook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.windows.x</th>\n",
              "      <td>xr</td>\n",
              "      <td>widget</td>\n",
              "      <td>motif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>misc.forsale</th>\n",
              "      <td>sale</td>\n",
              "      <td>offer</td>\n",
              "      <td>forsal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.autos</th>\n",
              "      <td>car</td>\n",
              "      <td>automot</td>\n",
              "      <td>auto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.motorcycles</th>\n",
              "      <td>dod</td>\n",
              "      <td>bike</td>\n",
              "      <td>motorcycl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.sport.baseball</th>\n",
              "      <td>basebal</td>\n",
              "      <td>philli</td>\n",
              "      <td>yanke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.sport.hockey</th>\n",
              "      <td>hockey</td>\n",
              "      <td>team</td>\n",
              "      <td>playoff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.crypt</th>\n",
              "      <td>clipper</td>\n",
              "      <td>encrypt</td>\n",
              "      <td>tap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.electronics</th>\n",
              "      <td>circuit</td>\n",
              "      <td>electron</td>\n",
              "      <td>tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.med</th>\n",
              "      <td>doctor</td>\n",
              "      <td>diseas</td>\n",
              "      <td>medic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.space</th>\n",
              "      <td>space</td>\n",
              "      <td>orbit</td>\n",
              "      <td>pat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soc.religion.christian</th>\n",
              "      <td>christian</td>\n",
              "      <td>distribut</td>\n",
              "      <td>god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.politics.guns</th>\n",
              "      <td>gun</td>\n",
              "      <td>waco</td>\n",
              "      <td>firearm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.politics.mideast</th>\n",
              "      <td>israel</td>\n",
              "      <td>isra</td>\n",
              "      <td>serdar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.politics.misc</th>\n",
              "      <td>theodor</td>\n",
              "      <td>clinton</td>\n",
              "      <td>libertarian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.religion.misc</th>\n",
              "      <td>christian</td>\n",
              "      <td>order</td>\n",
              "      <td>koresh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  0          1            2\n",
              "alt.atheism                 atheist      keith        islam\n",
              "comp.graphics               graphic       imag         anim\n",
              "comp.os.ms-windows.misc      window        win       driver\n",
              "comp.sys.ibm.pc.hardware    monitor    gateway  motherboard\n",
              "comp.sys.mac.hardware           mac       appl    powerbook\n",
              "comp.windows.x                   xr     widget        motif\n",
              "misc.forsale                   sale      offer       forsal\n",
              "rec.autos                       car    automot         auto\n",
              "rec.motorcycles                 dod       bike    motorcycl\n",
              "rec.sport.baseball          basebal     philli        yanke\n",
              "rec.sport.hockey             hockey       team      playoff\n",
              "sci.crypt                   clipper    encrypt          tap\n",
              "sci.electronics             circuit   electron           tv\n",
              "sci.med                      doctor     diseas        medic\n",
              "sci.space                     space      orbit          pat\n",
              "soc.religion.christian    christian  distribut          god\n",
              "talk.politics.guns              gun       waco      firearm\n",
              "talk.politics.mideast        israel       isra       serdar\n",
              "talk.politics.misc          theodor    clinton  libertarian\n",
              "talk.religion.misc        christian      order       koresh"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 689
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "RiohQCmehyxy",
        "outputId": "574e554b-0415-444c-96c1-a3100b217c0e"
      },
      "source": [
        "Df.transpose().head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt.atheism</th>\n",
              "      <th>comp.graphics</th>\n",
              "      <th>comp.os.ms-windows.misc</th>\n",
              "      <th>comp.sys.ibm.pc.hardware</th>\n",
              "      <th>comp.sys.mac.hardware</th>\n",
              "      <th>comp.windows.x</th>\n",
              "      <th>misc.forsale</th>\n",
              "      <th>rec.autos</th>\n",
              "      <th>rec.motorcycles</th>\n",
              "      <th>rec.sport.baseball</th>\n",
              "      <th>rec.sport.hockey</th>\n",
              "      <th>sci.crypt</th>\n",
              "      <th>sci.electronics</th>\n",
              "      <th>sci.med</th>\n",
              "      <th>sci.space</th>\n",
              "      <th>soc.religion.christian</th>\n",
              "      <th>talk.politics.guns</th>\n",
              "      <th>talk.politics.mideast</th>\n",
              "      <th>talk.politics.misc</th>\n",
              "      <th>talk.religion.misc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atheist</td>\n",
              "      <td>graphic</td>\n",
              "      <td>window</td>\n",
              "      <td>monitor</td>\n",
              "      <td>mac</td>\n",
              "      <td>xr</td>\n",
              "      <td>sale</td>\n",
              "      <td>car</td>\n",
              "      <td>dod</td>\n",
              "      <td>basebal</td>\n",
              "      <td>hockey</td>\n",
              "      <td>clipper</td>\n",
              "      <td>circuit</td>\n",
              "      <td>doctor</td>\n",
              "      <td>space</td>\n",
              "      <td>christian</td>\n",
              "      <td>gun</td>\n",
              "      <td>israel</td>\n",
              "      <td>theodor</td>\n",
              "      <td>christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>keith</td>\n",
              "      <td>imag</td>\n",
              "      <td>win</td>\n",
              "      <td>gateway</td>\n",
              "      <td>appl</td>\n",
              "      <td>widget</td>\n",
              "      <td>offer</td>\n",
              "      <td>automot</td>\n",
              "      <td>bike</td>\n",
              "      <td>philli</td>\n",
              "      <td>team</td>\n",
              "      <td>encrypt</td>\n",
              "      <td>electron</td>\n",
              "      <td>diseas</td>\n",
              "      <td>orbit</td>\n",
              "      <td>distribut</td>\n",
              "      <td>waco</td>\n",
              "      <td>isra</td>\n",
              "      <td>clinton</td>\n",
              "      <td>order</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>islam</td>\n",
              "      <td>anim</td>\n",
              "      <td>driver</td>\n",
              "      <td>motherboard</td>\n",
              "      <td>powerbook</td>\n",
              "      <td>motif</td>\n",
              "      <td>forsal</td>\n",
              "      <td>auto</td>\n",
              "      <td>motorcycl</td>\n",
              "      <td>yanke</td>\n",
              "      <td>playoff</td>\n",
              "      <td>tap</td>\n",
              "      <td>tv</td>\n",
              "      <td>medic</td>\n",
              "      <td>pat</td>\n",
              "      <td>god</td>\n",
              "      <td>firearm</td>\n",
              "      <td>serdar</td>\n",
              "      <td>libertarian</td>\n",
              "      <td>koresh</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  alt.atheism comp.graphics  ... talk.politics.misc talk.religion.misc\n",
              "0     atheist       graphic  ...            theodor          christian\n",
              "1       keith          imag  ...            clinton              order\n",
              "2       islam          anim  ...        libertarian             koresh\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 690
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbA-EIHe4UW0",
        "outputId": "f54b7fc0-32d3-4bc8-e2e6-87519c4161af"
      },
      "source": [
        "print(((modelNB.coef_)[0].shape),modelNB.coef_.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3099,) (20, 3099)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H1cA8uAK42r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1097181-39dd-43f2-cd3b-def683eb8b30"
      },
      "source": [
        "# Find the each category's most important top 3 features (words) for NB model and show with a dataframe\n",
        "\n",
        "featureList2 = []\n",
        "for i in range(len(target_groups)):\n",
        "  top3_2 = np.argsort(modelNB.coef_[i])[-3: ]\n",
        "  reversedTop3_2 = top3_2[::-1]\n",
        "  print(reversedTop3_2)\n",
        "  TargetFeatures2 = []\n",
        "  for j in reversedTop3_2:\n",
        "    TargetFeatures2.append(Feature_names[j])\n",
        "  featureList2.append(TargetFeatures2)\n",
        "print(featureList2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1198 2012 2394]\n",
            "[1374 1068 1219]\n",
            "[3039 1068  848]\n",
            "[ 846  423 2417]\n",
            "[1659  149 2140]\n",
            "[3039 1068 2151]\n",
            "[2379 1858 1921]\n",
            "[ 422  920 1204]\n",
            "[ 300  822 2327]\n",
            "[3087 1162 2739]\n",
            "[2739 1162 2064]\n",
            "[1539  913  482]\n",
            "[3044 1232 3059]\n",
            "[2012 1816 1721]\n",
            "[2574 1947 1576]\n",
            "[1198  489 2012]\n",
            "[1243 2012 2331]\n",
            "[ 175 2012 1479]\n",
            "[2012 1195 2783]\n",
            "[1198  489 2012]\n",
            "[['god', 'peopl', 'say'], ['imag', 'file', 'graphic'], ['window', 'file', 'driver'], ['drive', 'card', 'scsi'], ['mac', 'appl', 'problem'], ['window', 'file', 'program'], ['sale', 'new', 'offer'], ['car', 'engin', 'good'], ['bike', 'dod', 'ride'], ['year', 'game', 'team'], ['team', 'game', 'play'], ['key', 'encrypt', 'chip'], ['wire', 'ground', 'work'], ['peopl', 'msg', 'medic'], ['space', 'orbit', 'launch'], ['god', 'christian', 'peopl'], ['gun', 'peopl', 'right'], ['armenian', 'peopl', 'israel'], ['peopl', 'go', 'think'], ['god', 'christian', 'peopl']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "YMsMxnhNkrk2",
        "outputId": "2d237e26-b6d9-4a70-bd48-6f161ae7a6d1"
      },
      "source": [
        "Df2 = pd.DataFrame(featureList2, index=target_groups)\n",
        "Df2.head(20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>alt.atheism</th>\n",
              "      <td>god</td>\n",
              "      <td>peopl</td>\n",
              "      <td>say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.graphics</th>\n",
              "      <td>imag</td>\n",
              "      <td>file</td>\n",
              "      <td>graphic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.os.ms-windows.misc</th>\n",
              "      <td>window</td>\n",
              "      <td>file</td>\n",
              "      <td>driver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.sys.ibm.pc.hardware</th>\n",
              "      <td>drive</td>\n",
              "      <td>card</td>\n",
              "      <td>scsi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.sys.mac.hardware</th>\n",
              "      <td>mac</td>\n",
              "      <td>appl</td>\n",
              "      <td>problem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comp.windows.x</th>\n",
              "      <td>window</td>\n",
              "      <td>file</td>\n",
              "      <td>program</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>misc.forsale</th>\n",
              "      <td>sale</td>\n",
              "      <td>new</td>\n",
              "      <td>offer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.autos</th>\n",
              "      <td>car</td>\n",
              "      <td>engin</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.motorcycles</th>\n",
              "      <td>bike</td>\n",
              "      <td>dod</td>\n",
              "      <td>ride</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.sport.baseball</th>\n",
              "      <td>year</td>\n",
              "      <td>game</td>\n",
              "      <td>team</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rec.sport.hockey</th>\n",
              "      <td>team</td>\n",
              "      <td>game</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.crypt</th>\n",
              "      <td>key</td>\n",
              "      <td>encrypt</td>\n",
              "      <td>chip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.electronics</th>\n",
              "      <td>wire</td>\n",
              "      <td>ground</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.med</th>\n",
              "      <td>peopl</td>\n",
              "      <td>msg</td>\n",
              "      <td>medic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sci.space</th>\n",
              "      <td>space</td>\n",
              "      <td>orbit</td>\n",
              "      <td>launch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soc.religion.christian</th>\n",
              "      <td>god</td>\n",
              "      <td>christian</td>\n",
              "      <td>peopl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.politics.guns</th>\n",
              "      <td>gun</td>\n",
              "      <td>peopl</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.politics.mideast</th>\n",
              "      <td>armenian</td>\n",
              "      <td>peopl</td>\n",
              "      <td>israel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.politics.misc</th>\n",
              "      <td>peopl</td>\n",
              "      <td>go</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk.religion.misc</th>\n",
              "      <td>god</td>\n",
              "      <td>christian</td>\n",
              "      <td>peopl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 0          1        2\n",
              "alt.atheism                    god      peopl      say\n",
              "comp.graphics                 imag       file  graphic\n",
              "comp.os.ms-windows.misc     window       file   driver\n",
              "comp.sys.ibm.pc.hardware     drive       card     scsi\n",
              "comp.sys.mac.hardware          mac       appl  problem\n",
              "comp.windows.x              window       file  program\n",
              "misc.forsale                  sale        new    offer\n",
              "rec.autos                      car      engin     good\n",
              "rec.motorcycles               bike        dod     ride\n",
              "rec.sport.baseball            year       game     team\n",
              "rec.sport.hockey              team       game     play\n",
              "sci.crypt                      key    encrypt     chip\n",
              "sci.electronics               wire     ground     work\n",
              "sci.med                      peopl        msg    medic\n",
              "sci.space                    space      orbit   launch\n",
              "soc.religion.christian         god  christian    peopl\n",
              "talk.politics.guns             gun      peopl    right\n",
              "talk.politics.mideast     armenian      peopl   israel\n",
              "talk.politics.misc           peopl         go    think\n",
              "talk.religion.misc             god  christian    peopl"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 693
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "2E-aR__OktZk",
        "outputId": "c013aede-a5e2-4b25-e125-61532a95a940"
      },
      "source": [
        "Df2.transpose().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt.atheism</th>\n",
              "      <th>comp.graphics</th>\n",
              "      <th>comp.os.ms-windows.misc</th>\n",
              "      <th>comp.sys.ibm.pc.hardware</th>\n",
              "      <th>comp.sys.mac.hardware</th>\n",
              "      <th>comp.windows.x</th>\n",
              "      <th>misc.forsale</th>\n",
              "      <th>rec.autos</th>\n",
              "      <th>rec.motorcycles</th>\n",
              "      <th>rec.sport.baseball</th>\n",
              "      <th>rec.sport.hockey</th>\n",
              "      <th>sci.crypt</th>\n",
              "      <th>sci.electronics</th>\n",
              "      <th>sci.med</th>\n",
              "      <th>sci.space</th>\n",
              "      <th>soc.religion.christian</th>\n",
              "      <th>talk.politics.guns</th>\n",
              "      <th>talk.politics.mideast</th>\n",
              "      <th>talk.politics.misc</th>\n",
              "      <th>talk.religion.misc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>god</td>\n",
              "      <td>imag</td>\n",
              "      <td>window</td>\n",
              "      <td>drive</td>\n",
              "      <td>mac</td>\n",
              "      <td>window</td>\n",
              "      <td>sale</td>\n",
              "      <td>car</td>\n",
              "      <td>bike</td>\n",
              "      <td>year</td>\n",
              "      <td>team</td>\n",
              "      <td>key</td>\n",
              "      <td>wire</td>\n",
              "      <td>peopl</td>\n",
              "      <td>space</td>\n",
              "      <td>god</td>\n",
              "      <td>gun</td>\n",
              "      <td>armenian</td>\n",
              "      <td>peopl</td>\n",
              "      <td>god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>peopl</td>\n",
              "      <td>file</td>\n",
              "      <td>file</td>\n",
              "      <td>card</td>\n",
              "      <td>appl</td>\n",
              "      <td>file</td>\n",
              "      <td>new</td>\n",
              "      <td>engin</td>\n",
              "      <td>dod</td>\n",
              "      <td>game</td>\n",
              "      <td>game</td>\n",
              "      <td>encrypt</td>\n",
              "      <td>ground</td>\n",
              "      <td>msg</td>\n",
              "      <td>orbit</td>\n",
              "      <td>christian</td>\n",
              "      <td>peopl</td>\n",
              "      <td>peopl</td>\n",
              "      <td>go</td>\n",
              "      <td>christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>say</td>\n",
              "      <td>graphic</td>\n",
              "      <td>driver</td>\n",
              "      <td>scsi</td>\n",
              "      <td>problem</td>\n",
              "      <td>program</td>\n",
              "      <td>offer</td>\n",
              "      <td>good</td>\n",
              "      <td>ride</td>\n",
              "      <td>team</td>\n",
              "      <td>play</td>\n",
              "      <td>chip</td>\n",
              "      <td>work</td>\n",
              "      <td>medic</td>\n",
              "      <td>launch</td>\n",
              "      <td>peopl</td>\n",
              "      <td>right</td>\n",
              "      <td>israel</td>\n",
              "      <td>think</td>\n",
              "      <td>peopl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  alt.atheism comp.graphics  ... talk.politics.misc talk.religion.misc\n",
              "0         god          imag  ...              peopl                god\n",
              "1       peopl          file  ...                 go          christian\n",
              "2         say       graphic  ...              think              peopl\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 694
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAICwTYoGC-V"
      },
      "source": [
        "##example DFs are deleted because accidently i ran these example df cells. Then i deleted them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPWqanx2QgmX"
      },
      "source": [
        "# **Notebook & Report**\n",
        "\n",
        "Notebook: We may just look at your notebook results; so make sure each cell is run and outputs are there.\n",
        "\n",
        "Report: Write an at most 1/2 page summary of your approach to this problem at the end of your notebook; this should be like an abstract of a paper or the executive summary.\n",
        "\n",
        "Must include statements such as:\n",
        "\n",
        "( Include the problem definition: 1-2 lines )\n",
        "\n",
        "(Talk about any preprocessing you did, explain your reasoning)\n",
        "\n",
        "(Talk about train/test sets, size and how split)\n",
        "\n",
        "(State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the .. classifier (parameters=....) , giving classification accuracy of % on test data.\")\n",
        "\n",
        "(Comment on feature importances of models)\n",
        "\n",
        "(Comment on anything that you deem important/interesting)\n",
        "\n",
        "\n",
        "You will get full points from here as long as you have a good (enough) summary of your work, regardless of your best performance or what you have decided to talk about in the last few lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkzSQwJRHFE"
      },
      "source": [
        "# **Write your report in this cell**\n",
        "We have a dataset which contains huge number of texts in the format of mail and their classification in terms of subject. We are trying to predict the given text's classification.\n",
        "\n",
        "Firslty, we need to do some preprocessing to manipulate the dataset in a way that machine can process. We need to use vectorization to make a some kind of dataset of words. And this vectorization is sensitive to uppercase characters and counts them as a different word. So, we need to convert all characters to lowercase characters. Also, There are some meaningless words for machine such as 'is', 'are' etc. which are called stop_words. So, we will get rid of these words in our text examples. Another preprocessing material that wer used is stemming. A single word can be written in many different forms such as 'apply', 'applied' etc. so we need to get rid of these and take the root for our mapping like 'appl'. Last preprocessing is getting rid of punctuation marks.\n",
        "\n",
        "Training and test datas are came built in. So, we did not split them explicity. Also, training data set has 11314 instances and test data set has 7532 instances. So, it is not actually what we wanted to do in order to have a bigger portion of training data.\n",
        "\n",
        "We have obtained the best reult with the MultinomialNaiveBayes classifier with parameters of alpha = 0.5 and we obtained the accuracy of 75,35847052575677% on test data. \n",
        "\n",
        "Feature importance dataframes are very satisfying for humanbeing. Almost all of top 3 features are very related with the given, predicted class of text.\n",
        "\n",
        "In my opinion, it is interesting that how coefficients of MultinomialNaiveBayes classifier is all negative and their importance is not determined by absolute value. I really got stuck on that situation. At first i took absolute values of coefficients and result was wrong. Then, i spent so much time to understand what is wrong with my code. Then, i started to do something like debug like looking the numbers one by one, getting their index etc. When i was printing the coefficients group by group, i found out that all coefficients are negative and the most important one is the closer one to 0. Maybe i missed some point in lectures. I will look again to this topic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5luVvQnRJr7"
      },
      "source": [
        "# **Submission**\n",
        "You will submit this homework via SUCourse.\n",
        "\n",
        "\n",
        "Please read this document again before submitting it.\n",
        "\n",
        "Please submit your **\"share link\" INLINE in Sucourse submissions.** That is we should be able to click on the link and go there and run (and possibly also modify) your code.\n",
        "\n",
        "For us to be able to modify, in case of errors etc, you should get your \"share link\" as **share with anyone in edit mode** \n",
        "\n",
        "Download the **.ipynb and the .html** file and upload both of them to Sucourse.\n",
        " \n",
        "Please do your assignment individually, do not copy from a friend or the Internet. Plagiarized assignments will receive -100.\n"
      ]
    }
  ]
}